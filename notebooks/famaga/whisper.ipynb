{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4855fd-d481-496c-a2a0-1860c12dfad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203d26fd-12b5-4112-ac8f-daab10da50b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"medium\")\n",
    "# result = model.transcribe(\"audio.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8de6fe-95fd-497f-9a02-25c7d3405084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import hashlib\n",
    "import subprocess\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "text_cache = Path('cache')\n",
    "\n",
    "def sha1(input_string):\n",
    "    \"\"\"Helper to hash input strings\"\"\"\n",
    "    try:\n",
    "\n",
    "        # Step 5: Create a new SHA-1 hash object\n",
    "        hash_object = hashlib.sha1()\n",
    "\n",
    "        # Step 6: Update the hash object with the bytes-like object\n",
    "        hash_object.update(input_string.encode('utf-8'))\n",
    "\n",
    "        # Step 7: Get the hexadecimal representation of the hash\n",
    "        return hash_object.hexdigest()\n",
    "    except Exception as e:\n",
    "        raise ValueError(input_string) from e\n",
    "\n",
    "\n",
    "from functools import wraps\n",
    "import inspect\n",
    "import json\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "\n",
    "\n",
    "class CustomEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if hasattr(obj, 'to_dict'):\n",
    "            return obj.to_dict()\n",
    "        if isinstance(obj, pd.Int64Dtype):\n",
    "            return int(obj)  # Convert Int64 to a regular int\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "\n",
    "def stored(func):\n",
    "    \"\"\"\n",
    "    implements nix-like durable memoisation of function results.\n",
    "\n",
    "    Lazy way to avoid recomputing expensive calls. Expects results to be JSON-serializable\n",
    "    \"\"\"\n",
    "    @wraps(func)\n",
    "    def CACHE(*args, **kwargs):\n",
    "        name = func.__name__\n",
    "        meta = {}\n",
    "\n",
    "        meta[\"name\"] = name\n",
    "        meta[\"func\"] = inspect.getsource(func)\n",
    "        meta[\"args\"] = args\n",
    "        meta[\"kwargs\"] = kwargs\n",
    "\n",
    "        js = json.dumps(meta, cls=CustomEncoder)  # Using CustomEncoder\n",
    "        sha = hashlib.sha1(js.encode('utf-8'))\n",
    "\n",
    "        digest = sha.hexdigest()\n",
    "\n",
    "        path = text_cache / f\"{digest}-{name}.json\"\n",
    "\n",
    "        if path.exists():\n",
    "            with path.open('r') as r:\n",
    "                cached = json.load(r)\n",
    "            return cached[\"result\"]\n",
    "        result = func(*args, **kwargs)\n",
    "        meta[\"result\"] = result\n",
    "        with path.open('w') as w:\n",
    "            json.dump(meta, w, cls=CustomEncoder)  # Using CustomEncoder\n",
    "        return result\n",
    "\n",
    "    return CACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2d8a6ea-c187-4d50-95fa-975a8caee19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"medium\")\n",
    "\n",
    "\n",
    "@stored\n",
    "def transcribe(path: str):\n",
    "    return model.transcribe(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "91f839b5-2a19-490a-b776-1fb89522041a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valuamba/projs/components_agent_sales/venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import whisper\n",
    "\n",
    "# Enable GPU\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# Load Whisper model\n",
    "model = whisper.load_model(\"medium\")\n",
    "\n",
    "# Load audio file\n",
    "audio = whisper.load_audio(path)\n",
    "\n",
    "# Perform transcription\n",
    "result = model.transcribe(audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91821ea8-e1ae-4e57-a268-7a4d970ed3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "01:32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f181928c-0a5e-4adf-afa7-1954bde473cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/valuamba/Movies/2024-06-06 14-30-11.mkv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4f0db15f-fa1a-4ef3-b849-7b9d085f6ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/valuamba/Movies/2024-06-06 14-07-06.mkv'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0d87832e-bde4-4e81-8731-147a20b234ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valuamba/projs/components_agent_sales/venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "result = transcribe(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b3279a2a-f1eb-49e3-946f-49c2192938ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you',\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 2.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.44147413969039917,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9342081546783447},\n",
       "  {'id': 1,\n",
       "   'seek': 3000,\n",
       "   'start': 30.0,\n",
       "   'end': 33.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50414, 291, 50517],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.8645403385162354,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.7711876630783081},\n",
       "  {'id': 2,\n",
       "   'seek': 6000,\n",
       "   'start': 60.0,\n",
       "   'end': 63.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50414, 291, 50517],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.6374342441558838,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.6836725473403931},\n",
       "  {'id': 3,\n",
       "   'seek': 9000,\n",
       "   'start': 90.0,\n",
       "   'end': 93.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50414, 291, 50517],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.43512067198753357,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.6670457124710083},\n",
       "  {'id': 4,\n",
       "   'seek': 12000,\n",
       "   'start': 120.0,\n",
       "   'end': 123.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50414, 291, 50517],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3937567174434662,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.673494815826416},\n",
       "  {'id': 5,\n",
       "   'seek': 15000,\n",
       "   'start': 150.0,\n",
       "   'end': 153.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50414, 291, 50517],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.39780282974243164,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.6951719522476196},\n",
       "  {'id': 6,\n",
       "   'seek': 18000,\n",
       "   'start': 180.0,\n",
       "   'end': 183.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50414, 291, 50517],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4038430154323578,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.7149105072021484},\n",
       "  {'id': 7,\n",
       "   'seek': 21000,\n",
       "   'start': 210.0,\n",
       "   'end': 213.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50414, 291, 50517],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4117944538593292,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.7333829402923584},\n",
       "  {'id': 8,\n",
       "   'seek': 24000,\n",
       "   'start': 240.0,\n",
       "   'end': 243.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50414, 291, 50517],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4144987165927887,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.7500842809677124},\n",
       "  {'id': 9,\n",
       "   'seek': 27000,\n",
       "   'start': 270.0,\n",
       "   'end': 273.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50414, 291, 50517],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4202006161212921,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.7658482193946838},\n",
       "  {'id': 10,\n",
       "   'seek': 30000,\n",
       "   'start': 300.0,\n",
       "   'end': 303.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50414, 291, 50517],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.41424185037612915,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.7763118743896484},\n",
       "  {'id': 11,\n",
       "   'seek': 33000,\n",
       "   'start': 330.0,\n",
       "   'end': 333.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50414, 291, 50517],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4179835319519043,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.7864850163459778},\n",
       "  {'id': 12,\n",
       "   'seek': 36000,\n",
       "   'start': 360.0,\n",
       "   'end': 363.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50414, 291, 50517],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.41657140851020813,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.7962072491645813},\n",
       "  {'id': 13,\n",
       "   'seek': 39000,\n",
       "   'start': 390.0,\n",
       "   'end': 393.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50414, 291, 50517],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.41398176550865173,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.8021925091743469},\n",
       "  {'id': 14,\n",
       "   'seek': 42000,\n",
       "   'start': 420.0,\n",
       "   'end': 422.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.36844131350517273,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.8095933794975281},\n",
       "  {'id': 15,\n",
       "   'seek': 45000,\n",
       "   'start': 450.0,\n",
       "   'end': 453.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50414, 291, 50517],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3965435028076172,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.8376846313476562},\n",
       "  {'id': 16,\n",
       "   'seek': 48000,\n",
       "   'start': 480.0,\n",
       "   'end': 482.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.35311874747276306,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.8371081352233887},\n",
       "  {'id': 17,\n",
       "   'seek': 51000,\n",
       "   'start': 510.0,\n",
       "   'end': 512.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.34435948729515076,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.8565865755081177},\n",
       "  {'id': 18,\n",
       "   'seek': 54000,\n",
       "   'start': 540.0,\n",
       "   'end': 542.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3247816860675812,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.8714107871055603},\n",
       "  {'id': 19,\n",
       "   'seek': 57000,\n",
       "   'start': 570.0,\n",
       "   'end': 572.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3102931082248688,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.8802333474159241},\n",
       "  {'id': 20,\n",
       "   'seek': 60000,\n",
       "   'start': 600.0,\n",
       "   'end': 602.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.29654157161712646,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.8850045800209045},\n",
       "  {'id': 21,\n",
       "   'seek': 63000,\n",
       "   'start': 630.0,\n",
       "   'end': 632.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.290327250957489,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.8932679891586304},\n",
       "  {'id': 22,\n",
       "   'seek': 66000,\n",
       "   'start': 660.0,\n",
       "   'end': 662.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.28509169816970825,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.8981460928916931},\n",
       "  {'id': 23,\n",
       "   'seek': 69000,\n",
       "   'start': 690.0,\n",
       "   'end': 692.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.28186652064323425,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.900461733341217},\n",
       "  {'id': 24,\n",
       "   'seek': 72000,\n",
       "   'start': 720.0,\n",
       "   'end': 722.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.27862393856048584,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9051099419593811},\n",
       "  {'id': 25,\n",
       "   'seek': 75000,\n",
       "   'start': 750.0,\n",
       "   'end': 752.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.28248679637908936,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9073330760002136},\n",
       "  {'id': 26,\n",
       "   'seek': 78000,\n",
       "   'start': 780.0,\n",
       "   'end': 782.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2843318581581116,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.911726713180542},\n",
       "  {'id': 27,\n",
       "   'seek': 81000,\n",
       "   'start': 810.0,\n",
       "   'end': 812.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2858891487121582,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.914273738861084},\n",
       "  {'id': 28,\n",
       "   'seek': 84000,\n",
       "   'start': 840.0,\n",
       "   'end': 842.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.291189044713974,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9171084761619568},\n",
       "  {'id': 29,\n",
       "   'seek': 87000,\n",
       "   'start': 870.0,\n",
       "   'end': 872.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.2958095967769623,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9209663271903992},\n",
       "  {'id': 30,\n",
       "   'seek': 90000,\n",
       "   'start': 900.0,\n",
       "   'end': 902.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3091118335723877,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9234268665313721},\n",
       "  {'id': 31,\n",
       "   'seek': 93000,\n",
       "   'start': 930.0,\n",
       "   'end': 932.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.30872902274131775,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9243117570877075},\n",
       "  {'id': 32,\n",
       "   'seek': 96000,\n",
       "   'start': 960.0,\n",
       "   'end': 962.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3083668351173401,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9273390769958496},\n",
       "  {'id': 33,\n",
       "   'seek': 99000,\n",
       "   'start': 990.0,\n",
       "   'end': 992.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.32269957661628723,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9280901551246643},\n",
       "  {'id': 34,\n",
       "   'seek': 102000,\n",
       "   'start': 1020.0,\n",
       "   'end': 1022.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3351381719112396,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9304918050765991},\n",
       "  {'id': 35,\n",
       "   'seek': 105000,\n",
       "   'start': 1050.0,\n",
       "   'end': 1052.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3470291793346405,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9323520064353943},\n",
       "  {'id': 36,\n",
       "   'seek': 108000,\n",
       "   'start': 1080.0,\n",
       "   'end': 1082.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.35129669308662415,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.933085024356842},\n",
       "  {'id': 37,\n",
       "   'seek': 111000,\n",
       "   'start': 1110.0,\n",
       "   'end': 1112.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3633440136909485,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9320017695426941},\n",
       "  {'id': 38,\n",
       "   'seek': 114000,\n",
       "   'start': 1140.0,\n",
       "   'end': 1142.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3662012219429016,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9339650869369507},\n",
       "  {'id': 39,\n",
       "   'seek': 117000,\n",
       "   'start': 1170.0,\n",
       "   'end': 1172.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3798641562461853,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9366410970687866},\n",
       "  {'id': 40,\n",
       "   'seek': 120000,\n",
       "   'start': 1200.0,\n",
       "   'end': 1202.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3867819309234619,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.936307966709137},\n",
       "  {'id': 41,\n",
       "   'seek': 123000,\n",
       "   'start': 1230.0,\n",
       "   'end': 1232.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.38257715106010437,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.93702232837677},\n",
       "  {'id': 42,\n",
       "   'seek': 126000,\n",
       "   'start': 1260.0,\n",
       "   'end': 1262.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.39913761615753174,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9371058344841003},\n",
       "  {'id': 43,\n",
       "   'seek': 129000,\n",
       "   'start': 1290.0,\n",
       "   'end': 1292.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3980475962162018,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9342241883277893},\n",
       "  {'id': 44,\n",
       "   'seek': 132000,\n",
       "   'start': 1320.0,\n",
       "   'end': 1322.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.3977471888065338,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9343842267990112},\n",
       "  {'id': 45,\n",
       "   'seek': 135000,\n",
       "   'start': 1350.0,\n",
       "   'end': 1352.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.41485506296157837,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9364581108093262},\n",
       "  {'id': 46,\n",
       "   'seek': 138000,\n",
       "   'start': 1380.0,\n",
       "   'end': 1382.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.42015454173088074,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9343408942222595},\n",
       "  {'id': 47,\n",
       "   'seek': 141000,\n",
       "   'start': 1410.0,\n",
       "   'end': 1412.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4330019950866699,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9370412826538086},\n",
       "  {'id': 48,\n",
       "   'seek': 144000,\n",
       "   'start': 1440.0,\n",
       "   'end': 1442.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4267740845680237,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9334495663642883},\n",
       "  {'id': 49,\n",
       "   'seek': 147000,\n",
       "   'start': 1470.0,\n",
       "   'end': 1472.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4498809576034546,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9359310865402222},\n",
       "  {'id': 50,\n",
       "   'seek': 150000,\n",
       "   'start': 1500.0,\n",
       "   'end': 1502.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4417170286178589,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9325862526893616},\n",
       "  {'id': 51,\n",
       "   'seek': 153000,\n",
       "   'start': 1530.0,\n",
       "   'end': 1532.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4451068043708801,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.929643988609314},\n",
       "  {'id': 52,\n",
       "   'seek': 156000,\n",
       "   'start': 1560.0,\n",
       "   'end': 1562.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4488909840583801,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9330305457115173},\n",
       "  {'id': 53,\n",
       "   'seek': 159000,\n",
       "   'start': 1590.0,\n",
       "   'end': 1592.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.45455366373062134,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9313890933990479},\n",
       "  {'id': 54,\n",
       "   'seek': 162000,\n",
       "   'start': 1620.0,\n",
       "   'end': 1622.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4694441258907318,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9318757057189941},\n",
       "  {'id': 55,\n",
       "   'seek': 165000,\n",
       "   'start': 1650.0,\n",
       "   'end': 1652.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.47343677282333374,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9316054582595825},\n",
       "  {'id': 56,\n",
       "   'seek': 168000,\n",
       "   'start': 1680.0,\n",
       "   'end': 1682.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.46871307492256165,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9302469491958618},\n",
       "  {'id': 57,\n",
       "   'seek': 171000,\n",
       "   'start': 1710.0,\n",
       "   'end': 1712.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4898134768009186,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9317578077316284},\n",
       "  {'id': 58,\n",
       "   'seek': 174000,\n",
       "   'start': 1740.0,\n",
       "   'end': 1742.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5026952624320984,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9303761124610901},\n",
       "  {'id': 59,\n",
       "   'seek': 177000,\n",
       "   'start': 1770.0,\n",
       "   'end': 1772.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4921551048755646,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9304477572441101},\n",
       "  {'id': 60,\n",
       "   'seek': 180000,\n",
       "   'start': 1800.0,\n",
       "   'end': 1802.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.4990962743759155,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9279306530952454},\n",
       "  {'id': 61,\n",
       "   'seek': 183000,\n",
       "   'start': 1830.0,\n",
       "   'end': 1832.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5104623436927795,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9275253415107727},\n",
       "  {'id': 62,\n",
       "   'seek': 186000,\n",
       "   'start': 1860.0,\n",
       "   'end': 1862.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5166963338851929,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.92838054895401},\n",
       "  {'id': 63,\n",
       "   'seek': 189000,\n",
       "   'start': 1890.0,\n",
       "   'end': 1892.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.5339882969856262,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.9254476428031921},\n",
       "  {'id': 64,\n",
       "   'seek': 192000,\n",
       "   'start': 1920.0,\n",
       "   'end': 1922.06,\n",
       "   'text': ' you',\n",
       "   'tokens': [50364, 291, 50467],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.597511887550354,\n",
       "   'compression_ratio': 0.2727272727272727,\n",
       "   'no_speech_prob': 0.6311137676239014}],\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a8a0b6e-d4d7-4f96-bf46-b68a82ae0927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c708e-638c-41d4-84f8-f0e71289f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transcribe('/Users/valuamba/Movies/2024-06-04 14-42-39.mkv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81cd907-4037-47af-9e8a-1412a2113db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cfa95c-e209-41de-a4a4-75e7cef460f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transcription.txt', 'w') as f:\n",
    "    f.write(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeeb43a-2295-4bef-815c-4c11a4ac7ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_string = json.dumps(result, indent=4, ensure_ascii=False)\n",
    "print(json_string)\n",
    "\n",
    "with open('transcription.json', 'w') as f:\n",
    "    f.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4560c8-df47-45d0-b952-7384924117f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai_client = OpenAI()\n",
    "\n",
    "def get_gpt(content, model=\"gpt-4o\", temperature=0, max_tokens=1000, stream=True):\n",
    "    \"\"\"\n",
    "    Cached call to GPT.\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": content}]\n",
    "\n",
    "    if stream:\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model, \n",
    "            messages=messages, \n",
    "            temperature=temperature, \n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        collected_messages = []\n",
    "        for chunk in response:\n",
    "            if chunk.choices[0].delta.content:\n",
    "                print(chunk.choices[0].delta.content, end='')\n",
    "                collected_messages.append(chunk.choices[0].delta.content)\n",
    "    \n",
    "        content_str = ''.join(collected_messages)\n",
    "        return content_str\n",
    "    else:\n",
    "        completion = openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "        return completion.model_dump()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a240ee5-fea0-4395-8cfe-05fdeea32a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "По базе данных тоже все запросы. Количество запросов, которое прилетело в базу данных. Тут вопрос стоит по поводу инстанса. В инстанс или в саму базу данных. Начнем с того, что представляется возможным с инстанса. Мурбек. Я кому вещаю? А, я с закрытым микрофоном говорю. Да, да, да. С инстанса, с инстанса. Да, и количество запросов в байтах. Чтобы смотреть, видно должно быть ровненько в среднем. Ну так, плавненько. От дня в день. Если какие-то пошли спайки, то их надо будет смотреть, что это. Redis. Здесь стандартные метрики. Реквесты. Интересно. По всему. Весь входящий трафик в HRTech. Все, что в HRTech есть. Есть. Есть incoming трафик. И соответственно, процент ошибок. Все ошибки, которые у нас произошли. На процент ошибок посмотреть. 400-ки? Вообще, 400-ки, 500-ки, любые ошибки просто посмотреть. Все. Да, все ошибки. Там дальше будем разбираться. Может, будем уточнять вообще все ошибки за раз. И процент этих ошибок. И соответственно, трешхолд. И поэтому потом будем делать SLA и тому подобное. Так, processing time. Процессинг time. Процессинг time по реквесту. Скорее всего, мы можем получить где-нибудь из кубернетиса. Compute time мы, конечно, не сможем получить из кубернетиса. Нам надо будет это делать самим. Но это делаем в следующую атерацию. И не сейчас. CPU idle. Тут, понятно, надо разобраться, что мы отсюда можем получить. Здесь про CPU, про запас прочности, какой у нас имеется на текущий момент времени. Ну и вообще посмотреть в динамике, как это работает. Где у нас там high time, где у нас там low time. Примерно предсказать можно, но хотя бы понять в high time у нас сколько там осталось. 10% CPU или 80%. В среднем мы работаем на 10%. В high time до 20% поднимаемся. И 80% CPU у нас просто так стоит. Зачем оно нам тогда нужно? Дальше. Клиенты. Это наши клиентские библиотечки, через которые мы ходим в другие сервисы. То есть я нахожусь в сервисе A, хочу сделать запрос в сервис B. Для этого у меня есть клиентская библиотека для сервиса B. Я ее беру и начинаю работать с сервисом B через эту клиентскую библиотеку. В эти клиентские библиотеки необходимо внедрить VBHTTP нашу библиотечку, в которую добавят метрики все исходящие запросы из наших клиентских библиотек. И сколько там ошибок было, сколько тайм-аутов было и реквеста в персентилях. Так, отдельно вынесено RBC и AUS. RBC и AUS – это два самых нагрузочных сервисов. Их прямо отдельно. Высоконагруженных. Да, спасибо. Ну ладно, да. Давай-давай, еще какой-то? Да, просто аутхен перестает быть. Ну, пока так. Это так, да. RBC и аутхен, верно. Пока так, будем смотреть вообще. Если он перестанет быть таким, у него там в ноль все сойдет и... У него он сейчас, по сути, будет обрабатывать всем работу. Ну, пока что нужно. RBC точно будут все ходить. Так, топ-10 сервисов по RequestCant. Посмотреть вообще, кто у нас в топе. И Гошные метрики. Тут стандартные. На самом деле, по Гошным метрикам на моей предыдущей работе Гошные метрики – это называлось не Гошные метрики, а Performance. И там прямо отдельная, на самом деле, дашбарда. Там, конечно, все было и allocation, и горутин. Но там еще дополнительные какие-то формулы были. По Гошным метрикам... Ну, что мне было бы интересно? Наверное, горутины в основном. Горутины в основном. Есть они у нас. То есть они должны утилизироваться равномерно. Вот. Да-да-да, горутин у нас есть. А, и Temporal. Там по workflow, по activities. Сколько было запусков. Там вообще в Temporal прям фу-фу-фу, целая огромная морда.\n",
    "\"\"\"\n",
    "\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dabf0c3-5ab8-4529-8b37-c45e299ded49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size):\n",
    "    # Loop over the text in increments of chunk_size\n",
    "    for i in range(0, len(text), chunk_size):\n",
    "        yield text[i:i + chunk_size]\n",
    "\n",
    "# Example usage\n",
    "long_text = \"This is a very long text that we want to split into smaller chunks.\"\n",
    "chunk_size = 4000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2fa32e-dc7a-48c7-9eca-c0515f74959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@stored\n",
    "def get_metrics_from_context(snipped: str):\n",
    "    return get_gpt(f\"\"\"\n",
    "Перечисли метрики, которые упоминались в тексте:\n",
    "\n",
    "{snipped}\"\"\", max_tokens=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6df498-404e-484e-b505-fc9624fe91f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@stored\n",
    "def test_stored(resut):\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f95d28-c636-407e-807c-356c7bfa8559",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stored(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808a7491-66d4-4d9e-8005-0376e350d9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "responces = []\n",
    "\n",
    "for chunk in chunk_text(result['text'], chunk_size):\n",
    "    responces.append(get_metrics_from_context(chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0b00e8b2-4234-4254-a314-068e38176691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В вашем разговоре с руководителем обсуждались следующие задачи и договоренности:\n",
      "\n",
      "1. **Метрики по активным мобильным сессиям**:\n",
      "   - Необходимо запросить у Анастасии метрики по количеству людей, у которых нет активной мобильной сессии.\n",
      "   - Уточнить метрики УАУСа.\n",
      "\n",
      "2. **Переезд на новые кластера**:\n",
      "   - Все тикеты по АКСЕС и ЕЛ отправить на доску, где их будет разбирать девопсовая команда и стажеры.\n",
      "   - Ожидать решения по бордам в течение недели.\n",
      "\n",
      "3. **Интеграция поиска по сотруднику соц. информации**:\n",
      "   - Виталий сделал ручку поиска, которая дает ОРКС структуру и информацию о пользователе.\n",
      "   - Тестирование этой ручки и ревью, которое висит на Вансевиче. Возможно, попросить Влада помочь с ревью.\n",
      "\n",
      "4. **Обработка данных БАСКов и ОРКС**:\n",
      "   - Наставничество стажеров, которые будут помогать Ярику с переходом на новые рельсы и обратно в инфу.\n",
      "\n",
      "5. **Докхаб и дата-сорсы**:\n",
      "   - Распарсили все сервисы и ямлы сервисов HR-теха, собрали общий JSON и научились импортировать в докхаб.\n",
      "   - Необходимо собрать информацию о сервисе и прелинковать через дата-сорс.\n",
      "   - Дата-сорсы будут использоваться для получения статистики по ресурсам и процессам.\n",
      "   - Скрипты для сборки архитектуры HR-теха и создания дата-сорсов.\n",
      "\n",
      "6. **Парсинг коммитов и ченчлогов**:\n",
      "   - Марк скинул скрипт для парсинга коммитов и получения информации о тикетах.\n",
      "   - Необходим сервисный токен uTrack для получения summary задач.\n",
      "\n",
      "7. **Встречи и стандарты**:\n",
      "   - Нурбек может пропускать Daily встречи по средам, если это необходимо.\n",
      "\n",
      "Основные договоренности включают запрос метрик, отправку тикетов на доску, тестирование и ревью новых функций, сбор информации через дата-сорсы и настройку скриптов для автоматизации процессов."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'В вашем разговоре с руководителем обсуждались следующие задачи и договоренности:\\n\\n1. **Метрики по активным мобильным сессиям**:\\n   - Необходимо запросить у Анастасии метрики по количеству людей, у которых нет активной мобильной сессии.\\n   - Уточнить метрики УАУСа.\\n\\n2. **Переезд на новые кластера**:\\n   - Все тикеты по АКСЕС и ЕЛ отправить на доску, где их будет разбирать девопсовая команда и стажеры.\\n   - Ожидать решения по бордам в течение недели.\\n\\n3. **Интеграция поиска по сотруднику соц. информации**:\\n   - Виталий сделал ручку поиска, которая дает ОРКС структуру и информацию о пользователе.\\n   - Тестирование этой ручки и ревью, которое висит на Вансевиче. Возможно, попросить Влада помочь с ревью.\\n\\n4. **Обработка данных БАСКов и ОРКС**:\\n   - Наставничество стажеров, которые будут помогать Ярику с переходом на новые рельсы и обратно в инфу.\\n\\n5. **Докхаб и дата-сорсы**:\\n   - Распарсили все сервисы и ямлы сервисов HR-теха, собрали общий JSON и научились импортировать в докхаб.\\n   - Необходимо собрать информацию о сервисе и прелинковать через дата-сорс.\\n   - Дата-сорсы будут использоваться для получения статистики по ресурсам и процессам.\\n   - Скрипты для сборки архитектуры HR-теха и создания дата-сорсов.\\n\\n6. **Парсинг коммитов и ченчлогов**:\\n   - Марк скинул скрипт для парсинга коммитов и получения информации о тикетах.\\n   - Необходим сервисный токен uTrack для получения summary задач.\\n\\n7. **Встречи и стандарты**:\\n   - Нурбек может пропускать Daily встречи по средам, если это необходимо.\\n\\nОсновные договоренности включают запрос метрик, отправку тикетов на доску, тестирование и ревью новых функций, сбор информации через дата-сорсы и настройку скриптов для автоматизации процессов.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gpt(f\"\"\"\n",
    "Это лог моего разговора с руководитлем я Technical Project Manager, мы разрабатываем на Golang.\n",
    "Про какие задачи мы тут говорили и о чем договорились?\n",
    "\n",
    "{result['text']}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b95f54-b7eb-4e02-9d7e-0cab1659a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gpt(f\"\"\"\n",
    "Напиши UserStory, которая будет понятна DevOps разработчику по добавлению Grafana дашбордов, используй meeting logs:\n",
    "\n",
    "{'\\n'.join(responces)}\n",
    "\"\"\", max_tokens=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af32fd3-1590-4e1b-b777-00891388ab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a11f9ba-474c-4b5a-94bd-95702ba967e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab082dc-9960-45e1-abbb-fbb1e2a0139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83fec17-3dac-43f4-85f1-3fb505e2ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gpt(\"how to map DataFrame object to into dataclass with comprehetion?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee2a500-89d6-41ed-9369-18c1dbc49c51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "gpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
