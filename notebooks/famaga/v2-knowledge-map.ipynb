{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e02a7b92-e1d2-4d59-85ba-ac318db6ca67",
   "metadata": {},
   "source": [
    "# Knowledge Map Liquidity Sample\n",
    "\n",
    "This requires:\n",
    "\n",
    "- `camelot-py[base]`\n",
    "- `openai`\n",
    "- `pandas`\n",
    "\n",
    "And also [pdftotext](https://en.wikipedia.org/wiki/Pdftotext)\n",
    "\n",
    "## Part 1: \"Framework\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e92e0618-3ece-48d2-bc93-61a0e1e8eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define a few helper utilities\n",
    "\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "text_cache = Path('cache')\n",
    "\n",
    "def sha1(input_string):\n",
    "    \"\"\"Helper to hash input strings\"\"\"\n",
    "    try:\n",
    "\n",
    "        # Step 5: Create a new SHA-1 hash object\n",
    "        hash_object = hashlib.sha1()\n",
    "\n",
    "        # Step 6: Update the hash object with the bytes-like object\n",
    "        hash_object.update(input_string.encode('utf-8'))\n",
    "\n",
    "        # Step 7: Get the hexadecimal representation of the hash\n",
    "        return hash_object.hexdigest()\n",
    "    except Exception as e:\n",
    "        raise ValueError(input_string) from e\n",
    "        \n",
    "def pdftotext(source: str, target: Path):\n",
    "    \"\"\"Extract text from PDF. Requires pdftotext binary in the path\"\"\"\n",
    "    \n",
    "    command = [r\"C:\\Users\\MGroup\\Downloads\\xpdf-tools-win-4.05\\xpdf-tools-win-4.05\\bin64\\pdftotext.exe\", \"-enc\",\"UTF-8\",\n",
    "               source, target]\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        if Path(target).exists():\n",
    "            Path(target).unlink()\n",
    "        print(f\"{source}: {result.stdout} {result.stderr}\".strip())\n",
    "\n",
    "def extract_text(source):\n",
    "    \"\"\"Get text from PDF. Cache results to avoid recomputation\"\"\"\n",
    "    local = text_cache / sha1(source.name + \" > text\")\n",
    "\n",
    "    if local.exists():\n",
    "        return local\n",
    "    print(f\"extracting from {source}\")\n",
    "    print(f'target: {local}')\n",
    "    pdftotext(source, local)\n",
    "    return local\n",
    "\n",
    "def get_page_text(file):\n",
    "    \"\"\"Split extracted text into multiple pages\"\"\"\n",
    "    splits = extract_text(file).read_text().split(\"\\f\")\n",
    "\n",
    "    pages = []\n",
    "    for i, s in enumerate(splits):\n",
    "        pages.append(((i + 1), s))\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02c92840-b94d-4d7f-acee-00d2e94b2d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "import inspect\n",
    "def stored(func):\n",
    "    \"\"\"\n",
    "    implements nix-like durable memoisation of function results.\n",
    "\n",
    "    Lazy way to avoid recomputing expensive calls. Expects results to be JSON-serializable\n",
    "    \"\"\"\n",
    "    @wraps(func)\n",
    "    def CACHE(*args, **kwargs):\n",
    "        name = func.__name__\n",
    "        meta = {}\n",
    "\n",
    "        meta[\"name\"] = name\n",
    "        meta[\"func\"] = inspect.getsource(func)\n",
    "        meta[\"args\"] = args\n",
    "        meta[\"kwargs\"] = kwargs\n",
    "\n",
    "        js = json.dumps(meta)\n",
    "        sha = hashlib.sha1(js.encode('utf-8'))\n",
    "\n",
    "        digest = sha.hexdigest()\n",
    "\n",
    "        path = text_cache / f\"{digest}-{name}.json\"\n",
    "\n",
    "        if path.exists():\n",
    "            with path.open('r') as r:\n",
    "                cached = json.load(r)\n",
    "            return cached[\"result\"]\n",
    "        result = func(*args, **kwargs)\n",
    "        meta[\"result\"] = result\n",
    "        with path.open('w') as w:\n",
    "            json.dump(meta, w)\n",
    "        return result\n",
    "\n",
    "    return CACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b33560c-333b-49f8-8d83-bd4cb15ed9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import camelot\n",
    "\n",
    "@stored\n",
    "def extract_csvs(pdf, page, method):\n",
    "    \"\"\"Extract tables from the specified PDF page as CSV\"\"\"\n",
    "    try:\n",
    "        sourced = camelot.read_pdf(str(pdf), flavor=method, pages=str(page))\n",
    "        results = []\n",
    "        for s in sourced:\n",
    "            tbl = s.df.to_csv(index=False)\n",
    "            results.append(tbl)\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f'Error on {pdf}' + e)\n",
    "        return []\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f044ed47-1a16-40c4-a294-94a6c05b7cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "@stored\n",
    "def get_gpt(content, model=\"gpt-4-1106-preview\", temperature=0, max_tokens=1000):\n",
    "    \"\"\"\n",
    "    Cached call to GPT.\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": content}]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return completion.model_dump()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82df4b21-3435-405c-a68a-10e3d91c05b3",
   "metadata": {},
   "source": [
    "# Part 2: Extractors\n",
    "\n",
    "We have two:\n",
    "\n",
    "1. Simple extractor that determines company name for the annual report\n",
    "2. More complex extractor that gets liquidity values from the tables in annual report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b88e64a-e511-4c23-8456-b44998af759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_name(txt):\n",
    "\n",
    "    prompt = \"\"\"\n",
    "You are CFO-GPT. You read annual reports and identify the name of the company in that report. \n",
    "\n",
    "Respond only with the name of the company or business entity. Respond with an empty string, if none is found\n",
    "\n",
    "```txt\n",
    "$TXT\n",
    "```\"\"\".strip() + \"\\n\"\n",
    "    \n",
    "    filled = prompt.replace(\"$TXT\", txt)\n",
    "    result = get_gpt(filled)['choices'][0]['message']['content']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8322d518-d305-4f13-8171-b3747e50b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hey, GPTExtractMasterBot. I want to extract from tables in annual reports information about the liquidity. \n",
    "\n",
    "# What are the names of the tables that will contain this value? Focus only on the most likely and common table names. Answer with a python function that checks if string contains a table that is likely to contain liquidity information\n",
    "\n",
    "\n",
    "liquidity_tables = [\n",
    "    'balance sheet',\n",
    "    'cash flow statement',\n",
    "    'cash flows'\n",
    "]\n",
    "\n",
    "keywords = [\n",
    "    'cash and cash equivalents',\n",
    "    'cash flow from operating activities',\n",
    "    'free cash flow',\n",
    "    'liquid assets'\n",
    "]\n",
    "\n",
    "def contains_liquidity_data(txt):\n",
    "    \"\"\"\n",
    "    Check if the provided string contains a table name that is likely to contain liquidity information.\n",
    "\n",
    "    Args:\n",
    "    table_name (str): The name of the table to check.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the table_name is likely to contain liquidity information, False otherwise.\n",
    "    \"\"\"\n",
    "    # Lowercase the table_name to make the search case-insensitive\n",
    "    txt = txt.lower()\n",
    "    \n",
    "    # Define a list of common liquidity-related table names\n",
    "\n",
    "    \n",
    "    # Check if the table_name contains any of the liquidity-related table names\n",
    "    table_found = any(s in txt for s in liquidity_tables)\n",
    "    cell_found = any(s in txt for s in keywords)\n",
    "\n",
    "    return table_found and cell_found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c8fe015-e69d-4315-98ea-be9e2cf07179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fail_table(df) -> str:\n",
    "    \"\"\"Quick heuristic to check if extracted data frame looks valid\"\"\"\n",
    "    txt = df.to_csv()\n",
    "\n",
    "\n",
    "    if \"....\" in txt:\n",
    "        return \"looks like index\"\n",
    "\n",
    "    shape = df.shape\n",
    "\n",
    "    surface = shape[0] * shape[1]\n",
    "    if surface < 7:\n",
    "        return f\"Surface is only {surface}\"\n",
    "\n",
    "    ratio = len(txt) / surface\n",
    "\n",
    "    if ratio > 40:\n",
    "        return f\"Text to cell ratio is {ratio}\"\n",
    "\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "558ba2c0-359a-4bcc-bc39-3a98f9f549a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_liquidity_per_year(tables):\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    You are CFO-GPT. You read annual reports, looking for the amount of avalable liquidity (only cash and similar equivalents) in the annual reports.\n",
    "    \n",
    "    Pay attention to the units of measure of the tables. Return values as decimal number with a currency at the end.\n",
    "    \n",
    "    Answer with a json dictionary: `\"year\": \"Value UnitOfMeasurement Currency\"`. If value for the year is missing, then skip it.\n",
    "    \n",
    "    Do not write any code! Start your answer with \"```json\".\n",
    "    \n",
    "    # Source data to extract from\n",
    "    \n",
    "    Important! Pay attention to the units of measurement in each text chunk (usually at the beginning or the end of the chunk). \n",
    "    \n",
    "    $CSV\n",
    "    \n",
    "    \"\"\".strip() + \"\\n\"\n",
    "    \n",
    "    \n",
    "    csv_joined = \"\\n\".join(tables)\n",
    "    \n",
    "    \n",
    "    filled = prompt.replace(\"$CSV\", csv_joined)\n",
    "    \n",
    "    result = get_gpt(filled)['choices'][0]['message']['content']\n",
    "\n",
    "    try:\n",
    "    \n",
    "        data = json.loads(result.replace(\"```json\", \"\").replace(\"```\", \"\"))\n",
    "    except:\n",
    "        raise ValueError(result)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f628dcb5-bf95-4f12-bf1b-381408029b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading C:\\Users\\MGroup\\components_agent_sales\\notebooks\\famaga\\tiny-data\\Bellevue Group AG - Annual_Report_2022.pdf\n",
      "  Company name: Bellevue Group\n",
      "  Extracting liquidity\n",
      "    interesting pages: 35, 38, 51, 63, 64, 71, 86\n",
      "    found 8 tables\n",
      "Company map: {\n",
      "  \"company\": \"Bellevue Group\",\n",
      "  \"liquidity\": {\n",
      "    \"2022\": \"64681 CHF\",\n",
      "    \"2021\": \"84363 CHF\"\n",
      "  }\n",
      "}\n",
      "Reading C:\\Users\\MGroup\\components_agent_sales\\notebooks\\famaga\\tiny-data\\Christian Dior - Dior Annual Report as of December 31, 2022.pdf\n",
      "extracting from C:\\Users\\MGroup\\components_agent_sales\\notebooks\\famaga\\tiny-data\\Christian Dior - Dior Annual Report as of December 31, 2022.pdf\n",
      "target: cache\\e255cd9f881a7bb81caf73ed073834ab107acd32\n",
      "  Company name: Christian Dior\n",
      "  Extracting liquidity\n",
      "    interesting pages: 9, 42, 43, 44, 45, 216, 218, 223, 225, 227, 247, 250, 252, 297, 298\n",
      "Text to cell ratio is 41.71818181818182\n",
      "Text to cell ratio is 40.130434782608695\n",
      "Text to cell ratio is 71.62711864406779\n",
      "Text to cell ratio is 41.205128205128204\n",
      "Text to cell ratio is 67.12280701754386\n",
      "Text to cell ratio is 49.92857142857143\n",
      "    found 12 tables\n",
      "Company map: {\n",
      "  \"company\": \"Christian Dior\",\n",
      "  \"liquidity\": {\n",
      "    \"2022\": \"7588 EUR millions\",\n",
      "    \"2021\": \"8122 EUR millions\",\n",
      "    \"2020\": \"20358 EUR millions\"\n",
      "  }\n",
      "}\n",
      "Reading C:\\Users\\MGroup\\components_agent_sales\\notebooks\\famaga\\tiny-data\\UNIQA Insurance Group AG - UNIQA_JFB_2022_EN.pdf\n",
      "extracting from C:\\Users\\MGroup\\components_agent_sales\\notebooks\\famaga\\tiny-data\\UNIQA Insurance Group AG - UNIQA_JFB_2022_EN.pdf\n",
      "target: cache\\9d0255d7b22f454ab47e6fbe1599003ed5319ea3\n",
      "  Company name: UNIQA Insurance Group AG\n",
      "  Extracting liquidity\n",
      "    interesting pages: 65\n",
      "    found 1 tables\n",
      "Company map: {\n",
      "  \"company\": \"UNIQA Insurance Group AG\",\n",
      "  \"liquidity\": {\n",
      "    \"2022\": \"667.675 Thousand €\",\n",
      "    \"2021\": \"592.583 Thousand €\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "sources = Path(r\"C:\\Users\\MGroup\\components_agent_sales\\notebooks\\famaga\\tiny-data\").rglob(\"*.pdf\")\n",
    "\n",
    "# print(list(sources))\n",
    "\n",
    "knowledge_map = []\n",
    "\n",
    "for pdf in list(sources):\n",
    "    print(f\"Reading {pdf}\")\n",
    "    tables = []\n",
    "\n",
    "    raw_pages = get_page_text(pdf)\n",
    "\n",
    "    company_name = get_company_name(raw_pages[0][1] + \"\\n\" + raw_pages[1][1])\n",
    "    \n",
    "    print(f\"  Company name: {company_name}\")\n",
    "\n",
    "    print(f\"  Extracting liquidity\")    \n",
    "    pages = []    \n",
    "    for num, txt in raw_pages:\n",
    "        if contains_liquidity_data(txt):\n",
    "            pages.append((num, txt))\n",
    "\n",
    "    print(f\"    interesting pages: {', '.join([str(t[0]) for t in pages])}\")\n",
    "    \n",
    "            \n",
    "    \n",
    "    final = []\n",
    "    for page, txt in pages:\n",
    "        for method in ['stream', 'lattice']:\n",
    "            found = False\n",
    "\n",
    "            csvs = extract_csvs(str(pdf), page, method)\n",
    "\n",
    "            for csv in csvs:\n",
    "                df = pd.read_csv(StringIO(csv))\n",
    "                fail_reason = fail_table(df)\n",
    "                if fail_reason:\n",
    "                    print(fail_reason)\n",
    "                    continue\n",
    "                final.append(f\"\\n```csv\\n{csv}\\n```\\n\\n\")\n",
    "    print(f\"    found {len(final)} tables\")\n",
    "          \n",
    "\n",
    "    if not final:\n",
    "        print(f\"Nothing found for {pdf}\")\n",
    "        continue\n",
    "    liquidity = extract_liquidity_per_year(final)\n",
    "\n",
    "    \n",
    "\n",
    "    record = {\"company\": company_name, \"liquidity\": liquidity}\n",
    "    print(\"Company map: \" + json.dumps(record, indent=2, ensure_ascii=False))\n",
    "\n",
    "    knowledge_map.append(record)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79ec6a0b-aa88-45ac-ab2f-942c32c833a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'company': 'Bellevue Group',\n",
       "  'liquidity': {'2022': '64681 CHF', '2021': '84363 CHF'}},\n",
       " {'company': 'Christian Dior',\n",
       "  'liquidity': {'2022': '7588 EUR millions',\n",
       "   '2021': '8122 EUR millions',\n",
       "   '2020': '20358 EUR millions'}},\n",
       " {'company': 'UNIQA Insurance Group AG',\n",
       "  'liquidity': {'2022': '667.675 Thousand €', '2021': '592.583 Thousand €'}}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the final knowledge map\n",
    "knowledge_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "911eb55a-b073-4d32-b2cd-29e0243b0311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine which company has more liquidity, we need to compare the liquidity figures for the most recent year provided, which is 2022. However, we need to ensure that we are comparing the same currency or convert them to a common currency for an accurate comparison. The liquidity is provided in Swiss Francs (CHF) for Bellevue Group, and in Euros (EUR) for Christian Dior and UNIQA Insurance Group AG.\n",
      "\n",
      "From the provided data:\n",
      "\n",
      "- Bellevue Group has a liquidity of 64,681 CHF in 2022.\n",
      "- Christian Dior has a liquidity of 7,588 million EUR in 2022.\n",
      "- UNIQA Insurance Group AG has a liquidity of 667.675 thousand EUR in 2022.\n",
      "\n",
      "Without the current exchange rate, we cannot accurately convert CHF to EUR or vice versa. However, we can see that Christian Dior's liquidity is in the order of millions of Euros, which would be significantly higher than the liquidity of Bellevue Group in Swiss Francs or UNIQA Insurance Group AG's liquidity in thousands of Euros.\n",
      "\n",
      "Therefore, based on the provided figures and without needing to convert currencies, Christian Dior has the most liquidity in 2022 with 7,588 million EUR.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "You are CFO-GPT. Quickly answer, which of the companies has more liquidity, and how much? Don't make up information, if you are not certain.\n",
    "\n",
    "```json\n",
    "$MAP\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "filled = prompt.replace(\"$MAP\", json.dumps(knowledge_map))\n",
    "result = get_gpt(filled)['choices'][0]['message']['content']\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d117e4-726c-4f90-804c-77c385ed1bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
