{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbd8c3e-a77c-4b21-9829-063d10ce6639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_relevant_documents(\n",
    "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
    "    ) -> List[Document]:\n",
    "        if self.search_type == \"similarity\":\n",
    "            docs = self.vectorstore.similarity_search(query, **self.search_kwargs)\n",
    "        elif self.search_type == \"similarity_score_threshold\":\n",
    "            docs_and_similarities = (\n",
    "                self.vectorstore.similarity_search_with_relevance_scores(\n",
    "                    query, **self.search_kwargs\n",
    "                )\n",
    "            )\n",
    "            docs = [doc for doc, _ in docs_and_similarities]\n",
    "        elif self.search_type == \"mmr\":\n",
    "            docs = self.vectorstore.max_marginal_relevance_search(\n",
    "                query, **self.search_kwargs\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"search_type of {self.search_type} not allowed.\")\n",
    "        return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aae279e-c9ed-429a-891e-27d193030e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [doc.page_content for doc in documents]\n",
    "        metadatas = [doc.metadata for doc in documents]\n",
    "        return cls.from_texts(\n",
    "            texts=texts,\n",
    "            embedding=embedding,\n",
    "            metadatas=metadatas,\n",
    "            ids=ids,\n",
    "            collection_name=collection_name,\n",
    "            persist_directory=persist_directory,\n",
    "            client_settings=client_settings,\n",
    "            client=client,\n",
    "            collection_metadata=collection_metadata,\n",
    "            **kwargs,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c32daca-40e9-4489-82e0-b85ca9d5d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    " chroma_collection = cls(\n",
    "            collection_name=collection_name,\n",
    "            embedding_function=embedding,\n",
    "            persist_directory=persist_directory,\n",
    "            client_settings=?,\n",
    "            client=client,\n",
    "            collection_metadata=collection_metadata,\n",
    "            **kwargs,\n",
    "        )\n",
    "        if ids is None:\n",
    "            ids = [str(uuid.uuid1()) for _ in texts]\n",
    "        if hasattr(\n",
    "            chroma_collection._client, \"max_batch_size\"\n",
    "        ):  # for Chroma 0.4.10 and above\n",
    "            from chromadb.utils.batch_utils import create_batches\n",
    "\n",
    "            for batch in create_batches(\n",
    "                api=chroma_collection._client,\n",
    "                ids=ids,\n",
    "                metadatas=metadatas,\n",
    "                documents=texts,\n",
    "            ):\n",
    "                chroma_collection.add_texts(\n",
    "                    texts=batch[3] if batch[3] else [],\n",
    "                    metadatas=batch[2] if batch[2] else None,\n",
    "                    ids=batch[0],\n",
    "                )\n",
    "        else:\n",
    "            chroma_collection.add_texts(texts=texts, metadatas=metadatas, ids=ids)\n",
    "        return chroma_collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757decd3-b45b-4e02-9f52-1b4a46253f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(\n",
    "        self,\n",
    "        collection_name: str = _LANGCHAIN_DEFAULT_COLLECTION_NAME,\n",
    "        embedding_function: Optional[Embeddings] = None,\n",
    "        persist_directory: Optional[str] = None,\n",
    "        client_settings: Optional[chromadb.config.Settings] = None,\n",
    "        collection_metadata: Optional[Dict] = None,\n",
    "        client: Optional[chromadb.Client] = None,\n",
    "        relevance_score_fn: Optional[Callable[[float], float]] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize with a Chroma client.\"\"\"\n",
    "        try:\n",
    "            import chromadb\n",
    "            import chromadb.config\n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                \"Could not import chromadb python package. \"\n",
    "                \"Please install it with `pip install chromadb`.\"\n",
    "            )\n",
    "\n",
    "        if client is not None:\n",
    "            self._client_settings = client_settings\n",
    "            self._client = client\n",
    "            self._persist_directory = persist_directory\n",
    "        else:\n",
    "            if client_settings:\n",
    "                # If client_settings is provided with persist_directory specified,\n",
    "                # then it is \"in-memory and persisting to disk\" mode.\n",
    "                client_settings.persist_directory = (\n",
    "                    persist_directory or client_settings.persist_directory\n",
    "                )\n",
    "                if client_settings.persist_directory is not None:\n",
    "                    # Maintain backwards compatibility with chromadb < 0.4.0\n",
    "                    major, minor, _ = chromadb.__version__.split(\".\")\n",
    "                    if int(major) == 0 and int(minor) < 4:\n",
    "                        client_settings.chroma_db_impl = \"duckdb+parquet\"\n",
    "\n",
    "                _client_settings = client_settings\n",
    "            elif persist_directory:\n",
    "                # Maintain backwards compatibility with chromadb < 0.4.0\n",
    "                major, minor, _ = chromadb.__version__.split(\".\")\n",
    "                if int(major) == 0 and int(minor) < 4:\n",
    "                    _client_settings = chromadb.config.Settings(\n",
    "                        chroma_db_impl=\"duckdb+parquet\",\n",
    "                    )\n",
    "                else:\n",
    "                    _client_settings = chromadb.config.Settings(is_persistent=True)\n",
    "                _client_settings.persist_directory = persist_directory\n",
    "            else:\n",
    "                _client_settings = chromadb.config.Settings()\n",
    "            self._client_settings = _client_settings\n",
    "            self._client = chromadb.Client(_client_settings)\n",
    "            self._persist_directory = (\n",
    "                _client_settings.persist_directory or persist_directory\n",
    "            )\n",
    "\n",
    "        self._embedding_function = embedding_function\n",
    "        self._collection = self._client.get_or_create_collection(\n",
    "            name=collection_name,\n",
    "            embedding_function=None,\n",
    "            metadata=collection_metadata,\n",
    "        )\n",
    "        self.override_relevance_score_fn = relevance_score_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec40565f-ef48-4801-855b-49c875634584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./emails.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "for i, text in enumerate(texts):\n",
    "    text.metadata[\"source\"] = f\"{i}-pl\"\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a602d292-fcf3-4369-81a3-cac75e19fc10",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7958ed3f-5a4e-4800-ab8b-0d309fc6b3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import chromadb.config\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "import openai\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b08c3526-82c9-4966-ba8f-da6331e3670a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e8968ce-b973-4755-9a01-d22a85c5499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = 'test-col'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c1bde2-529e-454b-aca0-a4896ba4a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_settings = chromadb.config.Settings()\n",
    "pprint(client_settings.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da9eb20e-41e6-4c25-a00b-df0b85d57c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chromadb.api.client.Client at 0x7f10c05ef790>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = chromadb.Client(client_settings)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0985309-33df-4870-bade-c94344ec1a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(name=test-col)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = client.get_or_create_collection(name=collection_name, embedding_function=None)\n",
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6101a26-489c-4559-bb19-f9ec2ee7e241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Subject: Enquiry for Supply of Firetrol Battery Charger AS-2001 | AL RAMIZ\\u2028Date: Thu, 30 Nov 2023 15:50:44 +0400\\nFrom: Ramees Khan | AREC <ramees@arecuae.com>\\nTo: info@famaga.ae Dear Sir/Ma’am,\\nWe’re currently enquiring for Supply of Firetrol Battery Charger AS-2001 (Type 3AB LL-1580) Qty: 01 No.\\nPlease quote your best discounted prices and availability.\\nI have attached a picture below for your reference.\\u2028\\u2028Thanking you.\\nBest Regards,\\nRAMEES KHAN\\nGeneral Manager\\nM: +971-52-6927466 | E: ramees@arecuae.com\\nAL RAMIZ ELECT. CONT. LLC\\nA: Industrial Area 17, Sharjah - United Arab Emirates\\nA: P.O Box: 96286, Sharjah\\nT: +971-6-5356891\\nE: info@arecuae.com | W: www.arecuae.com\\n\\u2028Transformers/Maintenance, Erection & Testing | Rewinding – Transformers, Motors & Generators | Cables – Laying, Termination, Testing – HT & LT | Distribution Boards – MDB, SMDB, DB | Generator Alternator – Repair & Maintenance, Bus Bar Modification & Testing | MV, LV Electrical Panel – Installation & Testing | Hiring of all types of Testing Instruments – Oil Filter Plants, Oil Tanks, Vacuum Pumps, Crimping Tools & Generators.\\nDisclaimer: This e-mail and any attachments may contain confidential and privileged information. If you are not the intended recipient, please notify the sender immediately by return e-mail, delete this e-mail and destroy any copies. Any dissemination or use of this information by a person other than the intended recipient is unauthorized and may be illegal.', metadata={'source': '0-pl'})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = TextLoader(\"./emails.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    text.metadata[\"source\"] = f\"{i}-pl\"\n",
    "    \n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2f99def-212f-4647-bdfb-d4cad65c72fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['44c64bd0-acd7-11ee-8c92-898860aabb33']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "ids = [str(uuid.uuid1()) for _ in texts]\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de0ae889-be00-480c-ac86-128350eb9862",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0b184b7-4c5d-490c-8741-8f1bb3e82d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eca37d69-7b7e-4aa1-a179-ee48f6c4bcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "indices = []\n",
    "model_name = 'text-embedding-ada-002'\n",
    "chunk_size = 1000\n",
    "embedding_ctx_length = 8191\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(model_name)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7f54972-a3ca-46ed-bcfe-0f16d8ed8bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Subject: Enquiry for Supply of Firetrol Battery Charger AS-2001 | AL RAMIZ\\u2028Date: Thu, 30 Nov 2023 15:50:44 +0400\\nFrom: Ramees Khan | AREC <ramees@arecuae.com>\\nTo: info@famaga.ae Dear Sir/Ma’am,\\nWe’re currently enquiring for Supply of Firetrol Battery Charger AS-2001 (Type 3AB LL-1580) Qty: 01 No.\\nPlease quote your best discounted prices and availability.\\nI have attached a picture below for your reference.\\u2028\\u2028Thanking you.\\nBest Regards,\\nRAMEES KHAN\\nGeneral Manager\\nM: +971-52-6927466 | E: ramees@arecuae.com\\nAL RAMIZ ELECT. CONT. LLC\\nA: Industrial Area 17, Sharjah - United Arab Emirates\\nA: P.O Box: 96286, Sharjah\\nT: +971-6-5356891\\nE: info@arecuae.com | W: www.arecuae.com\\n\\u2028Transformers/Maintenance, Erection & Testing | Rewinding – Transformers, Motors & Generators | Cables – Laying, Termination, Testing – HT & LT | Distribution Boards – MDB, SMDB, DB | Generator Alternator – Repair & Maintenance, Bus Bar Modification & Testing | MV, LV Electrical Panel – Installation & Testing | Hiring of all types of Testing Instruments – Oil Filter Plants, Oil Tanks, Vacuum Pumps, Crimping Tools & Generators.\\nDisclaimer: This e-mail and any attachments may contain confidential and privileged information. If you are not the intended recipient, please notify the sender immediately by return e-mail, delete this e-mail and destroy any copies. Any dissemination or use of this information by a person other than the intended recipient is unauthorized and may be illegal.', metadata={'source': '0-pl'})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5cf5ca0-e39c-4b22-aefa-737f70f89281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "395"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = encoding.encode(text=texts[0].page_content)\n",
    "\n",
    "len(token)\n",
    "\n",
    "# len(texts[0].page_content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e6659d0-454f-4a35-b24d-5b2d3f259c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 8191, 16382]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicies = []\n",
    "tokens = []\n",
    "\n",
    "for j in range(0, len(token), embedding_ctx_length):\n",
    "    tokens.append(token[j : j + embedding_ctx_length])\n",
    "    indices.append(i)\n",
    "        \n",
    "list(range(0, 20000, embedding_ctx_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6930a7dd-708a-4cb6-a45a-7aea77c54783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "range(stop) -> range object\n",
       "range(start, stop[, step]) -> range object\n",
       "\n",
       "Return an object that produces a sequence of integers from start (inclusive)\n",
       "to stop (exclusive) by step.  range(i, j) produces i, i+1, i+2, ..., j-1.\n",
       "start defaults to 0, and stop is omitted!  range(4) produces 0, 1, 2, 3.\n",
       "These are exactly the valid indices for a list of 4 elements.\n",
       "When step is given, it specifies the increment (or decrement).\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "range??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e381370-9298-405a-8381-a8de84d7efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = embeddings.client.create(**kwargs)\n",
    "\n",
    "if any(len(d[\"embedding\"]) == 1 for d in response[\"data\"]) and not skip_empty:\n",
    "        import openai\n",
    "\n",
    "        raise openai.error.APIError(\"OpenAI API returned an empty embedding\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3af6a321-ebf7-4239-8730-2512015451bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.resources.embeddings.Embeddings at 0x7f10be38c150>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_client = openai.OpenAI().embeddings\n",
    "\n",
    "embedding_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd9c854-e719-43c3-8bbc-ed9ca91ca38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, text in enumerate(texts):\n",
    "    token = encoding.encode(text=text)\n",
    "\n",
    "    for j in range(0, len(token), self.embedding_ctx_length):\n",
    "        tokens.append(token[j : j + self.embedding_ctx_length])\n",
    "        indices.append(i)\n",
    "\n",
    "batched_embeddings: List[List[float]] = []\n",
    "\n",
    "for i in _iter:\n",
    "    response = embedding_client.create(input=tokens[i : i + _chunk_size])\n",
    "    if any(len(d[\"embedding\"]) == 1 for d in response[\"data\"]) and not skip_empty:\n",
    "        raise openai.error.APIError(\"OpenAI API returned an empty embedding\")\n",
    "\n",
    "    if not isinstance(response, dict):\n",
    "        response = response.dict()\n",
    "    batched_embeddings.extend(r[\"embedding\"] for r in response[\"data\"])\n",
    "\n",
    "results: List[List[List[float]]] = [[] for _ in range(len(texts))]\n",
    "num_tokens_in_batch: List[List[int]] = [[] for _ in range(len(texts))]\n",
    "for i in range(len(indices)):\n",
    "    if self.skip_empty and len(batched_embeddings[i]) == 1:\n",
    "        continue\n",
    "    results[indices[i]].append(batched_embeddings[i])\n",
    "    num_tokens_in_batch[indices[i]].append(len(tokens[i]))\n",
    "\n",
    "embeddings: List[List[float]] = [[] for _ in range(len(texts))]\n",
    "for i in range(len(texts)):\n",
    "    _result = results[i]\n",
    "    if len(_result) == 0:\n",
    "        average_embedded = embed_with_retry(\n",
    "                    self,\n",
    "                    input=\"\",\n",
    "                    **self._invocation_params,\n",
    "                )\n",
    "        if not isinstance(average_embedded, dict):\n",
    "            average_embedded = average_embedded.dict()\n",
    "        average = average_embedded[\"data\"][0][\"embedding\"]\n",
    "    else:\n",
    "        average = np.average(_result, axis=0, weights=num_tokens_in_batch[i])\n",
    "    embeddings[i] = (average / np.linalg.norm(average)).tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f25a2cc5-fd5d-4405-8f1f-2d9c446435a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mencoding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mallowed_special\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Union[Literal['all'], AbstractSet[str]]\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdisallowed_special\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Union[Literal['all'], Collection[str]]\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'all'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'list[int]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mallowed_special\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"all\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAbstractSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# noqa: B006\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdisallowed_special\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"all\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCollection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Encodes a string into tokens.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Special tokens are artificial tokens used to unlock capabilities from a model,\u001b[0m\n",
       "\u001b[0;34m        such as fill-in-the-middle. So we want to be careful about accidentally encoding special\u001b[0m\n",
       "\u001b[0;34m        tokens, since they can be used to trick a model into doing something we don't want it to do.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Hence, by default, encode will raise an error if it encounters text that corresponds\u001b[0m\n",
       "\u001b[0;34m        to a special token. This can be controlled on a per-token level using the `allowed_special`\u001b[0m\n",
       "\u001b[0;34m        and `disallowed_special` parameters. In particular:\u001b[0m\n",
       "\u001b[0;34m        - Setting `disallowed_special` to () will prevent this function from raising errors and\u001b[0m\n",
       "\u001b[0;34m          cause all text corresponding to special tokens to be encoded as natural text.\u001b[0m\n",
       "\u001b[0;34m        - Setting `allowed_special` to \"all\" will cause this function to treat all text\u001b[0m\n",
       "\u001b[0;34m          corresponding to special tokens to be encoded as special tokens.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        ```\u001b[0m\n",
       "\u001b[0;34m        >>> enc.encode(\"hello world\")\u001b[0m\n",
       "\u001b[0;34m        [31373, 995]\u001b[0m\n",
       "\u001b[0;34m        >>> enc.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"})\u001b[0m\n",
       "\u001b[0;34m        [50256]\u001b[0m\n",
       "\u001b[0;34m        >>> enc.encode(\"<|endoftext|>\", allowed_special=\"all\")\u001b[0m\n",
       "\u001b[0;34m        [50256]\u001b[0m\n",
       "\u001b[0;34m        >>> enc.encode(\"<|endoftext|>\")\u001b[0m\n",
       "\u001b[0;34m        # Raises ValueError\u001b[0m\n",
       "\u001b[0;34m        >>> enc.encode(\"<|endoftext|>\", disallowed_special=())\u001b[0m\n",
       "\u001b[0;34m        [27, 91, 437, 1659, 5239, 91, 29]\u001b[0m\n",
       "\u001b[0;34m        ```\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mallowed_special\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mallowed_special\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_tokens_set\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mdisallowed_special\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdisallowed_special\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_tokens_set\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mallowed_special\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mdisallowed_special\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisallowed_special\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mdisallowed_special\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisallowed_special\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0m_special_token_regex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisallowed_special\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mraise_disallowed_special_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_core_bpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_special\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeEncodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# BPE operates on bytes, but the regex operates on unicode. If we pass a str that is\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# invalid UTF-8 to Rust, it will rightfully complain. Here we do a quick and dirty\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# fixup for any surrogate pairs that may have sneaked their way into the text.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# Technically, this introduces a place where encode + decode doesn't roundtrip a Python\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# string, but given that this is input we want to support, maybe that's okay.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# Also we use errors=\"replace\" to handle weird things like lone surrogates.\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-16\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"surrogatepass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-16\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_core_bpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_special\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/projs/components_agent_sales/venv/lib/python3.11/site-packages/tiktoken/core.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoding.encode??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416154dc-1e0f-4a60-a4ef-171ce5748516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
