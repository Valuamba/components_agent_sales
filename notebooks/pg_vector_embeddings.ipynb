{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efe9b9cf-d3b6-4ee3-befb-2f237bcdb502",
   "metadata": {},
   "outputs": [],
   "source": [
    "PGVECTOR_CONNECTION_STRING='postgresql://admin:5tgb%25TGB@localhost:45048/famaga'\n",
    "PGVECTOR_COLLECTION_NAME='details'\n",
    "TOP_K = 3\n",
    "SIMILARITY_SEARCH_LIMIT=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4093dca-1a92-4033-9207-2e5306199167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "client = OpenAI(api_key = os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "EMBEDDINGS_MODEL = 'text-embedding-ada-002'\n",
    "INDEX_DIMENSIONS = 1536\n",
    "\n",
    "# print('OpenAI Engines: ', client.Engine.list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7a65287-59a2-472b-a17e-7ffda50b4996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pgvector\n",
      "  Obtaining dependency information for pgvector from https://files.pythonhosted.org/packages/ff/70/4121568743eff331240def4d0b0e949f3cd36f440435a69f967ebd1f0bc6/pgvector-0.2.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading pgvector-0.2.4-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting psycopg2-binary\n",
      "  Obtaining dependency information for psycopg2-binary from https://files.pythonhosted.org/packages/ce/85/62825cabc6aad53104b7b6d12eb2ad74737d268630032d07b74d4444cb72/psycopg2_binary-2.9.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading psycopg2_binary-2.9.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: tiktoken in ./venv/lib/python3.11/site-packages (0.5.2)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.11/site-packages (from pgvector) (1.26.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.11/site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./venv/lib/python3.11/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
      "Downloading pgvector-0.2.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading psycopg2_binary-2.9.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: psycopg2-binary, pgvector\n",
      "Successfully installed pgvector-0.2.4 psycopg2-binary-2.9.9\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pgvector psycopg2-binary tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc083f5b-2351-4a12-bb93-7ec18d89172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import psycopg2\n",
    "import pgvector\n",
    "from psycopg2.extras import execute_values\n",
    "from pgvector.psycopg2 import register_vector\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "492b96ac-fdb3-450b-b330-fa7c136f694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection = psycopg2.connect(PGVECTOR_CONNECTION_STRING)\n",
    "db_cursor = db_connection.cursor()\n",
    "db_connection.autocommit = True\n",
    "\n",
    "register_vector(db_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "695a1563-47f5-4387-9b71-5f258786bacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_cursor.execute('CREATE TABLE IF NOT EXISTS detail_brands (brand_id SERIAL PRIMARY KEY, name VARCHAR(200))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d4fa205-7b15-4a63-9066-6b1a9a80650d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>brand_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>986</td>\n",
       "      <td>Aignep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4990</td>\n",
       "      <td>GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>891</td>\n",
       "      <td>Airtac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>445</td>\n",
       "      <td>BRINKMANN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17000</td>\n",
       "      <td>Weiss Technik</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  brand_id          title\n",
       "0           0       986         Aignep\n",
       "1           1      4990            GMT\n",
       "2           2       891         Airtac\n",
       "3           3       445      BRINKMANN\n",
       "4           4     17000  Weiss Technik"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./assets/brands.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d874e90c-2335-427e-90da-dfd5fd8c46b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df.apply(lambda row: all(isinstance(row[col], str) for col in ['title', ]), axis=1)]\n",
    "\n",
    "values_str = ', '.join(filtered_df.apply(\n",
    "    lambda row: \"({brand_id}, '{name}')\".format(brand_id=row['brand_id'], name=row['title'].replace(\"'\", \"''\")), axis=1))\n",
    "print(values_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f452fa4-8001-49b9-91ca-bfbad7133243",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_cursor.execute(f\"\"\"\n",
    "INSERT INTO detail_brands (brand_id, name)\n",
    "VALUES {values_str}\n",
    "    \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed705fe0-497b-4fe5-bbb5-2edfc8c6df2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_cursor.execute('CREATE EXTENSION IF NOT EXISTS vector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf3a788d-9a9e-4b2f-ab16-6fa667252907",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_create_command = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {PGVECTOR_COLLECTION_NAME} (\n",
    "            brand_id SERIAL PRIMARY KEY,\n",
    "            name VARCHAR(200),\n",
    "            metadata JSON,\n",
    "            embedding VECTOR({INDEX_DIMENSIONS})\n",
    "            );\n",
    "            \"\"\"\n",
    "\n",
    "db_cursor.execute(table_create_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbad027e-e22a-44af-9bb7-dbfa57d9ba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_vector(text: str):\n",
    "    res = client.embeddings.create(input = [text], model=EMBEDDINGS_MODEL)\n",
    "    print(f'Generated embeddings for the string \"{text[0:100]}\", dimensions: {len(res.data[0].embedding)}')\n",
    "    return res.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80993c0d-9839-44cf-b56d-a849a56a6fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vector(db_cursor, doc, embeds):\n",
    "    try:\n",
    "        query = f\"\"\"\n",
    "            INSERT INTO {PGVECTOR_COLLECTION_NAME} (brand_id, name, embedding)\n",
    "            VALUES ({doc[\"brand_id\"]}, '{doc[\"title\"]}', '{embeds}')\n",
    "            ON CONFLICT (brand_id)\n",
    "            DO\n",
    "                UPDATE SET name = '{doc[\"title\"]}', embedding = '{embeds}'\n",
    "        \"\"\"\n",
    "        \n",
    "        db_cursor.execute(query)\n",
    "        print(f'Vector {doc[\"brand_id\"]} was added to the DB.')\n",
    "        return doc[\"title\"]\n",
    "    except Exception as e:\n",
    "        print(f\"[save_vector] execption of type {type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7414b98f-8430-4862-961b-8d3179f6a73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    embeds = get_embeddings_vector(row[\"title\"])\n",
    "    save_vector(db_cursor, row, embeds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1c7e48d-f2cb-4902-ae4e-95111a072d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "739e8045-4c0c-471b-8fd1-4530b00754db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "filtered_df = df[df.apply(lambda row: all(isinstance(row[col], str) for col in ['title', ]), axis=1)]\n",
    "list_of_dicts = filtered_df.to_dict(orient='records')\n",
    "\n",
    "batches = [list_of_dicts[i:i + batch_size] for i in range(0, len(list_of_dicts), batch_size)]\n",
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac724521-4ab2-443d-aa18-79f1a0146b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e746fc8-42cf-4427-9b8c-fe4ac474630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_batch(batch):\n",
    "    for row in batch:\n",
    "        try:\n",
    "            embeds = get_embeddings_vector(row[\"title\"])\n",
    "            save_vector(db_cursor, row, embeds)\n",
    "        except Exception as exc:\n",
    "            print(f'Row {row} generated an exception: {exc}')\n",
    "\n",
    "# with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "#     future_to_batch = {executor.submit(process_batch, batch): batch for batch in batches}\n",
    "#     for future in concurrent.futures.as_completed(future_to_batch):\n",
    "#         pass\n",
    "    \n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Submit all batches to the executor\n",
    "    future_to_batch = {executor.submit(process_batch, batch): batch for batch in batches}\n",
    "\n",
    "    # Iterate over the futures as they complete\n",
    "    for future in concurrent.futures.as_completed(future_to_batch):\n",
    "        batch = future_to_batch[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            # You can do something with the result here\n",
    "            # e.g., print(result)\n",
    "        except Exception as exc:\n",
    "            print(f'Batch generated an exception: {exc}')\n",
    "        else:\n",
    "            print(f'Batch processed successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "525cc9b4-c6ef-4af1-89d4-e29d757b25bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_relevant_messages(db_cursor, text, embeddings, k=int(TOP_K)):\n",
    "    try:\n",
    "        query = f\"\"\"\n",
    "            WITH vector_matches AS (\n",
    "                SELECT brand_id, name, embedding <=> '{embeddings}' AS distance\n",
    "                FROM {PGVECTOR_COLLECTION_NAME}\n",
    "            )\n",
    "            SELECT brand_id, name, distance\n",
    "            FROM vector_matches\n",
    "            ORDER BY distance\n",
    "            LIMIT '{k}';\n",
    "        \"\"\"\n",
    "        \n",
    "        db_cursor.execute(query)\n",
    "        all_matches = db_cursor.fetchall()\n",
    "        \n",
    "        relevant_matches = []\n",
    "        print('All matches:')\n",
    "        for doc in all_matches:\n",
    "            print(f'-- {round(doc[2], 2)}: {doc[1]}')\n",
    "            \n",
    "            if round(doc[2], 2) <= float(SIMILARITY_SEARCH_LIMIT):\n",
    "                relevant_matches.append({\n",
    "                    \"document\": doc,\n",
    "                    \"score\": doc[2]\n",
    "                    })\n",
    "\n",
    "        if len(relevant_matches) == 0:\n",
    "            print(\"No relevant matches found\")\n",
    "        else:\n",
    "            print(\"Relevant matches: \")\n",
    "            [print(f'-- {round(doc[\"score\"], 2)}: {doc[\"document\"][2]}') for doc in relevant_matches]\n",
    "        return relevant_matches\n",
    "    except Exception as e:\n",
    "        print(f\"[get_top_relevant_messages] {type(e).__name__} exception: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d1e0423-591a-4393-8956-b415d14ac38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings for the string \"ephymess\", dimensions: 1536\n",
      "All matches:\n",
      "-- 0.09: EPHY-MESS\n",
      "-- 0.17: EIFEM\n",
      "-- 0.17: Clemessy\n",
      "Relevant matches: \n",
      "-- 0.09: 0.08626945369293293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'document': (12033, 'EPHY-MESS', 0.08626945369293293),\n",
       "  'score': 0.08626945369293293}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_message = 'ephymess'\n",
    "get_top_relevant_messages(db_cursor, test_message, get_embeddings_vector(test_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecc91f2-5bad-481a-8a42-acf9a7d789c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualENV",
   "language": "python",
   "name": "virtualenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
