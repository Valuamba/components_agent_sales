{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e54eeae8-3f2b-4f88-8840-5e423dbe8af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scrapy\n",
      "  Obtaining dependency information for scrapy from https://files.pythonhosted.org/packages/08/66/22ed9609df4b6d94a66512572a11b35943a6cb36dc268f88ebfbede60be1/Scrapy-2.11.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached Scrapy-2.11.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting Twisted<23.8.0,>=18.9.0 (from scrapy)\n",
      "  Using cached Twisted-22.10.0-py3-none-any.whl (3.1 MB)\n",
      "Collecting cryptography>=36.0.0 (from scrapy)\n",
      "  Obtaining dependency information for cryptography>=36.0.0 from https://files.pythonhosted.org/packages/62/bd/69628ab50368b1beb900eb1de5c46f8137169b75b2458affe95f2f470501/cryptography-41.0.7-cp37-abi3-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading cryptography-41.0.7-cp37-abi3-manylinux_2_28_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting cssselect>=0.9.1 (from scrapy)\n",
      "  Using cached cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting itemloaders>=1.0.1 (from scrapy)\n",
      "  Using cached itemloaders-1.1.0-py3-none-any.whl (11 kB)\n",
      "Collecting parsel>=1.5.0 (from scrapy)\n",
      "  Using cached parsel-1.8.1-py2.py3-none-any.whl (17 kB)\n",
      "Collecting pyOpenSSL>=21.0.0 (from scrapy)\n",
      "  Obtaining dependency information for pyOpenSSL>=21.0.0 from https://files.pythonhosted.org/packages/db/de/007b832ad7a95e6a73745609bbe123c407aa2c46bb0b8f765c8718294e7f/pyOpenSSL-23.3.0-py3-none-any.whl.metadata\n",
      "  Downloading pyOpenSSL-23.3.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting queuelib>=1.4.2 (from scrapy)\n",
      "  Using cached queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting service-identity>=18.1.0 (from scrapy)\n",
      "  Obtaining dependency information for service-identity>=18.1.0 from https://files.pythonhosted.org/packages/0c/42/bf07f277b45da6e350df3314804aa2b5411e0938d3b78b4f17da2e1302c2/service_identity-23.1.0-py3-none-any.whl.metadata\n",
      "  Using cached service_identity-23.1.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting w3lib>=1.17.0 (from scrapy)\n",
      "  Obtaining dependency information for w3lib>=1.17.0 from https://files.pythonhosted.org/packages/82/e2/dcf8573d7153194eb673347cea1f9bbdb2a8e61030740fb6f50e4234a00b/w3lib-2.1.2-py3-none-any.whl.metadata\n",
      "  Using cached w3lib-2.1.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting zope.interface>=5.1.0 (from scrapy)\n",
      "  Obtaining dependency information for zope.interface>=5.1.0 from https://files.pythonhosted.org/packages/db/5f/46946b588c43eb28efe0e46f4cf455b1ed8b2d1ea62a21b0001c6610662f/zope.interface-6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading zope.interface-6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m130.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m296.1 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting protego>=0.1.15 (from scrapy)\n",
      "  Obtaining dependency information for protego>=0.1.15 from https://files.pythonhosted.org/packages/bc/16/14fd1ecdece2e1d87279fc09fbd2d55bae5fa033783c3547af631c74d718/Protego-0.3.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached Protego-0.3.0-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting itemadapter>=0.1.0 (from scrapy)\n",
      "  Using cached itemadapter-0.8.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: setuptools in /home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages (from scrapy) (68.1.2)\n",
      "Requirement already satisfied: packaging in /home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages (from scrapy) (23.2)\n",
      "Collecting tldextract (from scrapy)\n",
      "  Obtaining dependency information for tldextract from https://files.pythonhosted.org/packages/d0/de/3f37b2568115c7ebeae39508dc1092f04f3dc286f22ef30171baca9c9cf2/tldextract-5.1.1-py3-none-any.whl.metadata\n",
      "  Downloading tldextract-5.1.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: lxml>=4.4.1 in /home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages (from scrapy) (4.9.3)\n",
      "Collecting PyDispatcher>=2.0.5 (from scrapy)\n",
      "  Using cached PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages (from cryptography>=36.0.0->scrapy) (1.16.0)\n",
      "Collecting jmespath>=0.9.5 (from itemloaders>=1.0.1->scrapy)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages (from service-identity>=18.1.0->scrapy) (23.1.0)\n",
      "Collecting pyasn1 (from service-identity>=18.1.0->scrapy)\n",
      "  Obtaining dependency information for pyasn1 from https://files.pythonhosted.org/packages/d1/75/4686d2872bf2fc0b37917cbc8bbf0dd3a5cdb0990799be1b9cbf1e1eb733/pyasn1-0.5.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pyasn1-modules (from service-identity>=18.1.0->scrapy)\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting constantly>=15.1 (from Twisted<23.8.0,>=18.9.0->scrapy)\n",
      "  Obtaining dependency information for constantly>=15.1 from https://files.pythonhosted.org/packages/b8/40/c199d095151addf69efdb4b9ca3a4f20f70e20508d6222bffb9b76f58573/constantly-23.10.4-py3-none-any.whl.metadata\n",
      "  Downloading constantly-23.10.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting incremental>=21.3.0 (from Twisted<23.8.0,>=18.9.0->scrapy)\n",
      "  Using cached incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting Automat>=0.8.0 (from Twisted<23.8.0,>=18.9.0->scrapy)\n",
      "  Using cached Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting hyperlink>=17.1.1 (from Twisted<23.8.0,>=18.9.0->scrapy)\n",
      "  Using cached hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages (from Twisted<23.8.0,>=18.9.0->scrapy) (4.8.0)\n",
      "Requirement already satisfied: idna in /home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages (from tldextract->scrapy) (3.6)\n",
      "Requirement already satisfied: requests>=2.1.0 in /home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages (from tldextract->scrapy) (2.31.0)\n",
      "Collecting requests-file>=1.4 (from tldextract->scrapy)\n",
      "  Using cached requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages (from tldextract->scrapy) (3.13.1)\n",
      "Requirement already satisfied: six in /home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages (from Automat>=0.8.0->Twisted<23.8.0,>=18.9.0->scrapy) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=36.0.0->scrapy) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages (from requests>=2.1.0->tldextract->scrapy) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages (from requests>=2.1.0->tldextract->scrapy) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages (from requests>=2.1.0->tldextract->scrapy) (2023.11.17)\n",
      "Using cached Scrapy-2.11.0-py2.py3-none-any.whl (286 kB)\n",
      "Downloading cryptography-41.0.7-cp37-abi3-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m0m\n",
      "\u001b[?25hUsing cached Protego-0.3.0-py2.py3-none-any.whl (8.5 kB)\n",
      "Downloading pyOpenSSL-23.3.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached service_identity-23.1.0-py3-none-any.whl (12 kB)\n",
      "Using cached w3lib-2.1.2-py3-none-any.whl (21 kB)\n",
      "Downloading zope.interface-6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (249 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.1/249.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tldextract-5.1.1-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.7/97.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading constantly-23.10.4-py3-none-any.whl (13 kB)\n",
      "Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyDispatcher, incremental, zope.interface, w3lib, queuelib, pyasn1, protego, jmespath, itemadapter, hyperlink, cssselect, constantly, Automat, Twisted, requests-file, pyasn1-modules, parsel, cryptography, tldextract, service-identity, pyOpenSSL, itemloaders, scrapy\n",
      "Successfully installed Automat-22.10.0 PyDispatcher-2.0.7 Twisted-22.10.0 constantly-23.10.4 cryptography-41.0.7 cssselect-1.2.0 hyperlink-21.0.0 incremental-22.10.0 itemadapter-0.8.0 itemloaders-1.1.0 jmespath-1.0.1 parsel-1.8.1 protego-0.3.0 pyOpenSSL-23.3.0 pyasn1-0.5.1 pyasn1-modules-0.3.0 queuelib-1.6.2 requests-file-1.5.1 scrapy-2.11.0 service-identity-23.1.0 tldextract-5.1.1 w3lib-2.1.2 zope.interface-6.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5e94e30-6903-464f-ab4b-83721f07d20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "\n",
    "class MySpider(scrapy.Spider):\n",
    "    name = 'my_spider'\n",
    "    start_urls = ['https://lms.tough-dev.school/']\n",
    "\n",
    "    def parse(self, response):\n",
    "        # Extract the title of the current page\n",
    "        title = response.css('title::text').get()\n",
    "\n",
    "        # Extract the URL of the current page\n",
    "        url = response.url\n",
    "\n",
    "        # Return the extracted information\n",
    "        yield {\n",
    "            'title': title,\n",
    "            'url': url\n",
    "        }\n",
    "\n",
    "        # Follow links to other pages\n",
    "        for next_page in response.css('a::attr(href)').getall():\n",
    "            yield response.follow(next_page, self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "389d71f7-d0e6-4400-854a-58a4d269999c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 11:08:48 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: scrapybot)\n",
      "2023-12-29 11:08:48 [scrapy.utils.log] INFO: Versions: lxml 4.9.3.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.11.0 (main, Nov 11 2022, 23:21:45) [GCC 9.4.0], pyOpenSSL 23.3.0 (OpenSSL 3.1.4 24 Oct 2023), cryptography 41.0.7, Platform Linux-5.15.0-91-generic-x86_64-with-glibc2.35\n",
      "2023-12-29 11:08:48 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2023-12-29 11:08:48 [py.warnings] WARNING: /home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
      "\n",
      "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
      "\n",
      "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
      "  return cls(crawler)\n",
      "\n",
      "2023-12-29 11:08:48 [scrapy.extensions.telnet] INFO: Telnet Password: e804203e2a576d56\n"
     ]
    }
   ],
   "source": [
    "process = CrawlerProcess({\n",
    "    'USER_AGENT': 'Mozilla/5.0 (compatible; MySpider/1.0)',\n",
    "    'LOG_LEVEL': 'INFO',\n",
    "})\n",
    "\n",
    "# Start the spider\n",
    "process.crawl(MySpider)\n",
    "process.start()  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "723f1947-2f81-4e23-894d-68304fc7db62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unhandled error in Deferred:\n",
      "2023-12-29 13:08:16 [twisted] CRITICAL: Unhandled error in Deferred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages/scrapy/crawler.py\", line 265, in crawl\n",
      "    return self._crawl(crawler, *args, **kwargs)\n",
      "  File \"/home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages/scrapy/crawler.py\", line 269, in _crawl\n",
      "    d = crawler.crawl(*args, **kwargs)\n",
      "  File \"/home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages/twisted/internet/defer.py\", line 1947, in unwindGenerator\n",
      "    return _cancellableInlineCallbacks(gen)\n",
      "  File \"/home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages/twisted/internet/defer.py\", line 1857, in _cancellableInlineCallbacks\n",
      "    _inlineCallbacks(None, gen, status, _copy_context())\n",
      "--- <exception caught here> ---\n",
      "  File \"/home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages/twisted/internet/defer.py\", line 1697, in _inlineCallbacks\n",
      "    result = context.run(gen.send, result)\n",
      "  File \"/home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages/scrapy/crawler.py\", line 156, in crawl\n",
      "    self._apply_settings()\n",
      "  File \"/home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages/scrapy/crawler.py\", line 134, in _apply_settings\n",
      "    self.extensions = ExtensionManager.from_crawler(self)\n",
      "  File \"/home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages/scrapy/middleware.py\", line 90, in from_crawler\n",
      "    return cls.from_settings(crawler.settings, crawler)\n",
      "  File \"/home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages/scrapy/middleware.py\", line 66, in from_settings\n",
      "    mwcls = load_object(clspath)\n",
      "  File \"/home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages/scrapy/utils/misc.py\", line 79, in load_object\n",
      "    mod = import_module(module)\n",
      "  File \"/home/valuamba/.asdf/installs/python/3.11.0/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1206, in _gcd_import\n",
      "    \n",
      "  File \"<frozen importlib._bootstrap>\", line 1178, in _find_and_load\n",
      "    \n",
      "  File \"<frozen importlib._bootstrap>\", line 1149, in _find_and_load_unlocked\n",
      "    \n",
      "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
      "    \n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "    \n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "    \n",
      "  File \"/home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages/scrapy/extensions/feedexport.py\", line 24, in <module>\n",
      "    from scrapy.extensions.postprocessing import PostProcessingManager\n",
      "  File \"/home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages/scrapy/extensions/postprocessing.py\", line 7, in <module>\n",
      "    from lzma import LZMAFile\n",
      "  File \"/home/valuamba/.asdf/installs/python/3.11.0/lib/python3.11/lzma.py\", line 27, in <module>\n",
      "    from _lzma import *\n",
      "builtins.ModuleNotFoundError: No module named '_lzma'\n",
      "\n",
      "2023-12-29 13:08:16 [twisted] CRITICAL: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages/twisted/internet/defer.py\", line 1697, in _inlineCallbacks\n",
      "    result = context.run(gen.send, result)\n",
      "  File \"/home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages/scrapy/crawler.py\", line 156, in crawl\n",
      "    self._apply_settings()\n",
      "  File \"/home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages/scrapy/crawler.py\", line 134, in _apply_settings\n",
      "    self.extensions = ExtensionManager.from_crawler(self)\n",
      "  File \"/home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages/scrapy/middleware.py\", line 90, in from_crawler\n",
      "    return cls.from_settings(crawler.settings, crawler)\n",
      "  File \"/home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages/scrapy/middleware.py\", line 66, in from_settings\n",
      "    mwcls = load_object(clspath)\n",
      "  File \"/home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages/scrapy/utils/misc.py\", line 79, in load_object\n",
      "    mod = import_module(module)\n",
      "  File \"/home/valuamba/.asdf/installs/python/3.11.0/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1206, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1178, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1149, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages/scrapy/extensions/feedexport.py\", line 24, in <module>\n",
      "    from scrapy.extensions.postprocessing import PostProcessingManager\n",
      "  File \"/home/valuamba/projs/components_agent_sales/venv/lib/python3.11/site-packages/scrapy/extensions/postprocessing.py\", line 7, in <module>\n",
      "    from lzma import LZMAFile\n",
      "  File \"/home/valuamba/.asdf/installs/python/3.11.0/lib/python3.11/lzma.py\", line 27, in <module>\n",
      "    from _lzma import *\n",
      "ModuleNotFoundError: No module named '_lzma'\n"
     ]
    }
   ],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f63d13f-fa99-46d2-b58f-6bb37032ba07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
